{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2a24a9e-d4b9-403f-8932-298134edd885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import duckdb\n",
    "import lance\n",
    "import pyarrow.dataset as ds\n",
    "from datafusion import SessionContext, col, lit\n",
    "from deltalake import DeltaTable\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a2b60d-e9bc-4089-8279-89624ca9fd68",
   "metadata": {},
   "source": [
    "## 1e9 duckdb + Delta Lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd308cb7-3270-4859-9ac5-f29b8a97fde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56 s, sys: 17 s, total: 1min 13s\n",
      "Wall time: 24.2 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "      <th>id3</th>\n",
       "      <th>id4</th>\n",
       "      <th>id5</th>\n",
       "      <th>id6</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id043</td>\n",
       "      <td>id035</td>\n",
       "      <td>id0004875485</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>733428</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>75.21594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id1    id2           id3  id4  id5     id6  v1  v2        v3\n",
       "0  id043  id035  id0004875485    8   18  733428   4   4  75.21594"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "delta_1e9_v1 = DeltaTable(\n",
    "    f\"{pathlib.Path.home()}/data/deltalake/G1_1e9_1e2_0_0\", version=1\n",
    ").to_pyarrow_dataset()\n",
    "duckdb.query(\"select * from delta_1e9_v1 where v3 = 75.21594\").to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfdf051d-b9c1-4428-8ed6-2b8e79f9b3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 55.9 s, sys: 17.4 s, total: 1min 13s\n",
      "Wall time: 24.6 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "      <th>id3</th>\n",
       "      <th>id4</th>\n",
       "      <th>id5</th>\n",
       "      <th>id6</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id043</td>\n",
       "      <td>id035</td>\n",
       "      <td>id0004875485</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>733428</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>75.21594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id1    id2           id3  id4  id5     id6  v1  v2        v3\n",
       "0  id043  id035  id0004875485    8   18  733428   4   4  75.21594"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "delta_1e9_v1 = DeltaTable(\n",
    "    f\"{pathlib.Path.home()}/data/deltalake/G1_1e9_1e2_0_0\", version=2\n",
    ").to_pyarrow_dataset()\n",
    "duckdb.query(\"select * from delta_1e9_v1 where v3 = 75.21594\").to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bb4017a-5cba-40d3-b1c1-e31c1e2e1dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.66 s, sys: 819 ms, total: 3.48 s\n",
      "Wall time: 1.32 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "      <th>id3</th>\n",
       "      <th>id4</th>\n",
       "      <th>id5</th>\n",
       "      <th>id6</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id043</td>\n",
       "      <td>id035</td>\n",
       "      <td>id0004875485</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>733428</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>75.21594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id1    id2           id3  id4  id5     id6  v1  v2        v3\n",
       "0  id043  id035  id0004875485    8   18  733428   4   4  75.21594"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "delta_1e9_v1 = DeltaTable(\n",
    "    f\"{pathlib.Path.home()}/data/deltalake/G1_1e9_1e2_0_0\", version=3\n",
    ").to_pyarrow_dataset()\n",
    "duckdb.query(\"select * from delta_1e9_v1 where v3 = 75.21594\").to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8437c613-5985-4869-8591-e3847147a2c3",
   "metadata": {},
   "source": [
    "## 1e9 duckdb + Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74b62f03-1d35-4e8b-891e-bf8c8ceabd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 30s, sys: 13.1 s, total: 1min 43s\n",
      "Wall time: 17.9 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "      <th>id3</th>\n",
       "      <th>id4</th>\n",
       "      <th>id5</th>\n",
       "      <th>id6</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id043</td>\n",
       "      <td>id035</td>\n",
       "      <td>id0004875485</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>733428</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>75.21594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id1    id2           id3  id4  id5     id6  v1  v2        v3\n",
       "0  id043  id035  id0004875485    8   18  733428   4   4  75.21594"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "parquet_1e9_path = f\"{pathlib.Path.home()}/data/G1_1e9_1e2_0_0.parquet\"\n",
    "parquet_1e9 = pa.dataset.dataset(parquet_1e9_path, format=\"parquet\")\n",
    "duckdb.query(\"select * from parquet_1e9 where v3 = 75.21594\").to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6005fcc1-f26d-4404-bfc1-7bfbc5256006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow._parquet.FileMetaData object at 0x12967d1d0>\n",
       "  created_by: parquet-cpp-arrow version 11.0.0\n",
       "  num_columns: 9\n",
       "  num_rows: 1000000000\n",
       "  num_row_groups: 50467\n",
       "  format_version: 2.6\n",
       "  serialized_size: 47438984"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "parquet_file = pq.ParquetFile(parquet_1e9_path)\n",
    "parquet_file.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18848fb-d1ec-40ff-bb11-04896d714b02",
   "metadata": {},
   "source": [
    "## Convert 1e8 to lance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4b7beaa-6c35-462b-8d76-092d03794725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import lance\n",
    "import pyarrow as pa\n",
    "import pyarrow.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aba5b2d-3cfd-4487-bcb4-72dce6dafc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"{pathlib.Path.home()}/data/G1_1e8_1e2_0_0.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d956efcd-d597-4537-af39-eb9dd21f2ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.6 s, sys: 12.2 s, total: 25.8 s\n",
      "Wall time: 17.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lance.dataset.LanceDataset at 0x12221cd00>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "parquet = pa.dataset.dataset(path, format=\"parquet\")\n",
    "lance.write_dataset(parquet, f\"{pathlib.Path.home()}/data/G1_1e8_1e2_0_0.lance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cb7adac-ec57-4bae-97dd-db242debde3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.83 s, sys: 2.6 s, total: 4.43 s\n",
      "Wall time: 4.92 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "      <th>id3</th>\n",
       "      <th>id4</th>\n",
       "      <th>id5</th>\n",
       "      <th>id6</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id002</td>\n",
       "      <td>id041</td>\n",
       "      <td>id0000451508</td>\n",
       "      <td>86</td>\n",
       "      <td>81</td>\n",
       "      <td>364984</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>75.21594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id1    id2           id3  id4  id5     id6  v1  v2        v3\n",
       "0  id002  id041  id0000451508   86   81  364984   3   9  75.21594"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "dataset = lance.dataset(f\"{pathlib.Path.home()}/data/G1_1e8_1e2_0_0.lance\")\n",
    "duckdb.query(\"select * from dataset where v3 = 75.21594\").to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "495d58a2-c34d-4127-b170-e0b70d06cf3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌───────────┬───────┐\n",
       "│    v3     │ count │\n",
       "│  double   │ int64 │\n",
       "├───────────┼───────┤\n",
       "│ 88.294451 │     1 │\n",
       "│ 66.172531 │     1 │\n",
       "│ 99.491438 │     1 │\n",
       "└───────────┴───────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duckdb.query(\n",
    "    \"select v3, count(*) as count from dataset group by v3 having count = 1 limit 3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd7e942-436e-47c2-9afd-99f672cd9fc1",
   "metadata": {},
   "source": [
    "## Convert 1e9 to lance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0afbfee5-3000-4af6-9dd3-a1bef0ea1644",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"{pathlib.Path.home()}/data/G1_1e9_1e2_0_0.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35d3d573-31d9-4051-a600-85820fd68b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 18s, sys: 2min 4s, total: 4min 23s\n",
      "Wall time: 3min 3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lance.dataset.LanceDataset at 0x12229f220>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "parquet = pa.dataset.dataset(path, format=\"parquet\")\n",
    "lance.write_dataset(parquet, f\"{pathlib.Path.home()}/data/G1_1e9_1e2_0_0.lance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f923ddd-7343-40ee-98e4-13bfaee35ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.3 s, sys: 26.5 s, total: 44.9 s\n",
      "Wall time: 49 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "      <th>id3</th>\n",
       "      <th>id4</th>\n",
       "      <th>id5</th>\n",
       "      <th>id6</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id043</td>\n",
       "      <td>id035</td>\n",
       "      <td>id0004875485</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>733428</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>75.21594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id1    id2           id3  id4  id5     id6  v1  v2        v3\n",
       "0  id043  id035  id0004875485    8   18  733428   4   4  75.21594"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "dataset_1e9 = lance.dataset(f\"{pathlib.Path.home()}/data/G1_1e9_1e2_0_0.lance\")\n",
    "duckdb.query(\"select * from dataset_1e9 where v3 = 75.21594\").to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d162bc2-47dc-443c-94ac-18d68ada021e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌───────────┬───────┐\n",
       "│    v3     │ count │\n",
       "│  double   │ int64 │\n",
       "├───────────┼───────┤\n",
       "│  75.21594 │     1 │\n",
       "│ 54.307981 │     1 │\n",
       "│ 55.345451 │     1 │\n",
       "└───────────┴───────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duckdb.query(\n",
    "    \"select v3, count(*) as count from dataset_1e9 group by v3 having count = 1 limit 3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe91d1a-3e84-481d-91ee-55003f2aceab",
   "metadata": {},
   "source": [
    "## 1e9 DataFusion + Delta Lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2bdea21b-b259-49eb-8f2e-82a90f86512c",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_1e9 = DeltaTable(f\"{pathlib.Path.home()}/data/delta/G1_1e9_1e2_0_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9839060a-dc79-44ba-85cd-ff7f53ec0b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.16 ms, sys: 3.43 ms, total: 7.58 ms\n",
      "Wall time: 5.07 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ctx.register_dataset(\"my_dataset_1e9\", table.to_pyarrow_dataset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2807c83c-d18e-4791-8846-d4f3fa999ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame()\n",
      "+-------+-------+--------------+-----+-----+--------+----+----+----------+\n",
      "| id1   | id2   | id3          | id4 | id5 | id6    | v1 | v2 | v3       |\n",
      "+-------+-------+--------------+-----+-----+--------+----+----+----------+\n",
      "| id002 | id041 | id0000451508 | 86  | 81  | 364984 | 3  | 9  | 75.21594 |\n",
      "+-------+-------+--------------+-----+-----+--------+----+----+----------+\n",
      "CPU times: user 9.47 s, sys: 1.93 s, total: 11.4 s\n",
      "Wall time: 2.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res = ctx.sql(\"select * from my_dataset_1e9 where v3 = 75.21594\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b6f51f-a1d7-4f44-ad70-d3050044ed3b",
   "metadata": {},
   "source": [
    "## MDS 1e8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a44a73b-4671-4aec-acf1-5b117e2588bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from streaming.base.converters import dataframeToMDS\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7054d0b-4b78-47f1-94c5-8055f1cd46cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/10 00:39:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22455463-9cb7-4ff4-8aa6-0f11f0aa2fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "parquet_1e8_path = f\"{pathlib.Path.home()}/data/G1_1e8_1e2_0_0.parquet\"\n",
    "pdf = spark.read.parquet(parquet_1e8_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3296759a-1a1f-42a2-be2f-e9092d809814",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = f\"{pathlib.Path.home()}/data/G1_1e8_1e2_0_0.mds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6c6aea2-a1fa-4614-8523-a4cdbf79f287",
   "metadata": {},
   "outputs": [],
   "source": [
    "mds_kwargs = {'out': out_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "597048bc-c3f8-4c58-95ee-8f82e11e45af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "User's discretion required: columns arg is missing from mds_kwargs. Will be auto inferred\n",
      "Auto inferred schema: {'id1': 'str', 'id2': 'str', 'id3': 'str', 'id4': 'int64', 'id5': 'int64', 'id6': 'int64', 'v1': 'int64', 'v2': 'int64', 'v3': 'float64'}\n",
      "[Stage 2:======================================================>  (22 + 1) / 23]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 68.8 ms, sys: 28.2 ms, total: 97 ms\n",
      "Wall time: 3min 38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/Users/matthew.powers/data/G1_1e8_1e2_0_0.mds', 0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "dataframeToMDS(pdf, merge_index=True, mds_kwargs=mds_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e356eeba-7ecf-4063-9f3b-fef4fe77114a",
   "metadata": {},
   "source": [
    "## MDS 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd1e40a0-8cf4-413f-bd49-0edec2eb0f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_1e9_path = f\"{pathlib.Path.home()}/data/G1_1e9_1e2_0_0.parquet\"\n",
    "pdf = spark.read.parquet(parquet_1e9_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6f97fba-6f40-4104-bf44-a286425c635f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = f\"{pathlib.Path.home()}/data/G1_1e9_1e2_0_0.mds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d7ceed2-dee0-4c42-8a5e-48df2ae9c23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mds_kwargs = {'out': out_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6634a0c6-65d1-42b9-a29c-00272807a3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "User's discretion required: columns arg is missing from mds_kwargs. Will be auto inferred\n",
      "Auto inferred schema: {'id1': 'str', 'id2': 'str', 'id3': 'str', 'id4': 'int64', 'id5': 'int64', 'id6': 'int64', 'v1': 'int64', 'v2': 'int64', 'v3': 'float64'}\n",
      "23/10/10 00:49:55 ERROR Utils: Uncaught exception in thread stdout writer for python3\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "\tat shaded.parquet.org.apache.thrift.protocol.TCompactProtocol.readBinary(TCompactProtocol.java:708)\n",
      "\tat org.apache.parquet.format.InterningProtocol.readBinary(InterningProtocol.java:220)\n",
      "\tat shaded.parquet.org.apache.thrift.protocol.TProtocolUtil.skip(TProtocolUtil.java:102)\n",
      "\tat shaded.parquet.org.apache.thrift.protocol.TProtocolUtil.skip(TProtocolUtil.java:138)\n",
      "\tat shaded.parquet.org.apache.thrift.protocol.TProtocolUtil.skip(TProtocolUtil.java:112)\n",
      "\tat shaded.parquet.org.apache.thrift.protocol.TProtocolUtil.skip(TProtocolUtil.java:112)\n",
      "\tat shaded.parquet.org.apache.thrift.protocol.TProtocolUtil.skip(TProtocolUtil.java:138)\n",
      "\tat shaded.parquet.org.apache.thrift.protocol.TProtocolUtil.skip(TProtocolUtil.java:112)\n",
      "\tat shaded.parquet.org.apache.thrift.protocol.TProtocolUtil.skip(TProtocolUtil.java:138)\n",
      "\tat shaded.parquet.org.apache.thrift.protocol.TProtocolUtil.skip(TProtocolUtil.java:60)\n",
      "\tat org.apache.parquet.format.event.SkippingFieldConsumer.consumeField(Consumers.java:149)\n",
      "\tat org.apache.parquet.format.event.Consumers$DelegatingFieldConsumer.consumeField(Consumers.java:92)\n",
      "\tat org.apache.parquet.format.event.EventBasedThriftReader.readStructContent(EventBasedThriftReader.java:70)\n",
      "\tat org.apache.parquet.format.event.EventBasedThriftReader.readStruct(EventBasedThriftReader.java:54)\n",
      "\tat org.apache.parquet.format.Util.readFileMetaData(Util.java:334)\n",
      "\tat org.apache.parquet.format.Util.readFileMetaData(Util.java:180)\n",
      "\tat org.apache.parquet.format.converter.ParquetMetadataConverter$3.visit(ParquetMetadataConverter.java:1446)\n",
      "\tat org.apache.parquet.format.converter.ParquetMetadataConverter$3.visit(ParquetMetadataConverter.java:1437)\n",
      "\tat org.apache.parquet.format.converter.ParquetMetadataConverter$SkipMetadataFilter.accept(ParquetMetadataConverter.java:1183)\n",
      "\tat org.apache.parquet.format.converter.ParquetMetadataConverter.readParquetMetadata(ParquetMetadataConverter.java:1437)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.readFooter(ParquetFileReader.java:583)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.<init>(ParquetFileReader.java:777)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.open(ParquetFileReader.java:658)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:53)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:39)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat.footerFileMetaData$lzycompute$1(ParquetFileFormat.scala:211)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat.footerFileMetaData$1(ParquetFileFormat.scala:210)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat.$anonfun$buildReaderWithPartitionValues$2(ParquetFileFormat.scala:213)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$Lambda$2602/629457522.apply(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:228)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:290)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:125)\n",
      "Exception in thread \"stdout writer for python3\" java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "\tat shaded.parquet.org.apache.thrift.protocol.TCompactProtocol.readBinary(TCompactProtocol.java:708)\n",
      "\tat org.apache.parquet.format.InterningProtocol.readBinary(InterningProtocol.java:220)\n",
      "\tat shaded.parquet.org.apache.thrift.protocol.TProtocolUtil.skip(TProtocolUtil.java:102)\n",
      "\tat shaded.parquet.org.apache.thrift.protocol.TProtocolUtil.skip(TProtocolUtil.java:138)\n",
      "\tat shaded.parquet.org.apache.thrift.protocol.TProtocolUtil.skip(TProtocolUtil.java:112)\n",
      "\tat shaded.parquet.org.apache.thrift.protocol.TProtocolUtil.skip(TProtocolUtil.java:112)\n",
      "\tat shaded.parquet.org.apache.thrift.protocol.TProtocolUtil.skip(TProtocolUtil.java:138)\n",
      "\tat shaded.parquet.org.apache.thrift.protocol.TProtocolUtil.skip(TProtocolUtil.java:112)\n",
      "\tat shaded.parquet.org.apache.thrift.protocol.TProtocolUtil.skip(TProtocolUtil.java:138)\n",
      "\tat shaded.parquet.org.apache.thrift.protocol.TProtocolUtil.skip(TProtocolUtil.java:60)\n",
      "\tat org.apache.parquet.format.event.SkippingFieldConsumer.consumeField(Consumers.java:149)\n",
      "\tat org.apache.parquet.format.event.Consumers$DelegatingFieldConsumer.consumeField(Consumers.java:92)\n",
      "\tat org.apache.parquet.format.event.EventBasedThriftReader.readStructContent(EventBasedThriftReader.java:70)\n",
      "\tat org.apache.parquet.format.event.EventBasedThriftReader.readStruct(EventBasedThriftReader.java:54)\n",
      "\tat org.apache.parquet.format.Util.readFileMetaData(Util.java:334)\n",
      "\tat org.apache.parquet.format.Util.readFileMetaData(Util.java:180)\n",
      "\tat org.apache.parquet.format.converter.ParquetMetadataConverter$3.visit(ParquetMetadataConverter.java:1446)\n",
      "\tat org.apache.parquet.format.converter.ParquetMetadataConverter$3.visit(ParquetMetadataConverter.java:1437)\n",
      "\tat org.apache.parquet.format.converter.ParquetMetadataConverter$SkipMetadataFilter.accept(ParquetMetadataConverter.java:1183)\n",
      "\tat org.apache.parquet.format.converter.ParquetMetadataConverter.readParquetMetadata(ParquetMetadataConverter.java:1437)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.readFooter(ParquetFileReader.java:583)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.<init>(ParquetFileReader.java:777)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileReader.open(ParquetFileReader.java:658)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:53)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFooterReader.readFooter(ParquetFooterReader.java:39)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat.footerFileMetaData$lzycompute$1(ParquetFileFormat.scala:211)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat.footerFileMetaData$1(ParquetFileFormat.scala:210)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat.$anonfun$buildReaderWithPartitionValues$2(ParquetFileFormat.scala:213)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$Lambda$2602/629457522.apply(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:228)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:290)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:125)\n",
      "23/10/10 00:52:10 WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)29]\n",
      "23/10/10 00:52:20 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval\n",
      "\tat org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)\n",
      "\tat org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)\n",
      "\tat org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)\n",
      "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1107)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:314)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\t... 13 more\n",
      "[Stage 5:>                                                       (0 + 10) / 229]\r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dataframeToMDS(pdf, merge_index=True, mds_kwargs=mds_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eeb6e0-89c2-4542-a23d-04e3a06fed70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mosaic-340",
   "language": "python",
   "name": "mosaic-340"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
